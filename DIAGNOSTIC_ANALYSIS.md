# Diagnostic Analysis: Why Files Aren't Being Copied

## Summary

Based on my analysis of your codebase and configuration, I've identified **5 potential failure points** where files can be dropped during the copy process. Let me walk you through each one and how to diagnose them.

---

## The 5 Failure Points

### 1. **Pattern Matching Failures** ‚ö†Ô∏è HIGH RISK

**What happens:** Files don't match any copy rule pattern and are silently skipped.

**Where it happens:**
- `webhook_handler_new.go` line 349-352
- If `matchResult.Matched == false`, the file is skipped with `continue`

**Your config has these patterns:**
```yaml
# Rule 1-3, 5-6, 9-10: Prefix patterns
pattern: "mflix/client/"
pattern: "mflix/server/java-spring/"
pattern: "mflix/server/js-express/"
pattern: "mflix/server/python-fastapi/"

# Rule 2, 6, 10: Regex patterns  
pattern: "^mflix/server/java-spring/(?P<file>.+)$"
pattern: "^mflix/server/js-express/(?P<file>.+)$"
pattern: "^mflix/server/python-fastapi/(?P<file>.+)$"

# Rule 4, 8, 12: Glob patterns
pattern: "mflix/README-JAVA-SPRING.md"
pattern: "mflix/README-JAVASCRIPT-EXPRESS.md"
pattern: "mflix/README-PYTHON-FASTAPI.md"
pattern: "mflix/.gitignore-java"
pattern: "mflix/.gitignore-js"
pattern: "mflix/.gitignore-python"
```

**Common issues:**
- ‚ùå Files outside `mflix/` directory won't match ANY rule
- ‚ùå Files in `mflix/` root (not in subdirectories) won't match most rules
- ‚ùå Regex patterns require EXACT match (anchored with `^` and `$`)
- ‚ùå Prefix patterns need trailing slash to match subdirectories correctly

**Example failures:**
```
mflix/README.md                    ‚Üí NO MATCH (not in any pattern)
mflix/docker-compose.yml           ‚Üí NO MATCH (not in any pattern)
mflix/package.json                 ‚Üí NO MATCH (not in any pattern)
mflix/server/java-spring/.env      ‚Üí EXCLUDED (exclude_patterns)
mflix/client/README.md             ‚Üí EXCLUDED (exclude_patterns)
```

**How to diagnose:**
```bash
# Check logs for "file skipped - no matching rules"
grep "file skipped" /path/to/logs

# Look for the skipped_files array in logs
grep "skipped_files" /path/to/logs
```

---

### 2. **Path Transformation Failures** ‚ö†Ô∏è MEDIUM RISK

**What happens:** File matches a pattern, but path transformation fails due to missing variables.

**Where it happens:**
- `webhook_handler_new.go` line 401-410
- If `PathTransformer.Transform()` returns an error, the file is skipped with `return`

**Your config uses these transformations:**
```yaml
# Prefix patterns use ${relative_path}
path_transform: "client/${relative_path}"
path_transform: "server/${file}"

# Regex patterns use ${file} (from named capture group)
path_transform: "server/${file}"

# Glob patterns use literal paths
path_transform: "README.md"
path_transform: ".gitignore"
```

**Common issues:**
- ‚ùå Using `${file}` variable but pattern doesn't extract it (e.g., prefix pattern)
- ‚ùå Using `${relative_path}` but pattern is regex (doesn't provide it)
- ‚ùå Typo in variable name: `${files}` instead of `${file}`
- ‚ùå Unreplaced variables like `${lang}` when pattern doesn't extract `lang`

**Example failures:**
```yaml
# BAD: Prefix pattern doesn't extract ${file}
source_pattern:
  type: "prefix"
  pattern: "mflix/client/"
path_transform: "client/${file}"  # ‚ùå ${file} not available!

# GOOD: Use ${relative_path} instead
path_transform: "client/${relative_path}"  # ‚úÖ Works!
```

**How to diagnose:**
```bash
# Check logs for "failed to transform path"
grep "failed to transform path" /path/to/logs

# Look for "unreplaced variables" errors
grep "unreplaced variables" /path/to/logs
```

---

### 3. **File Retrieval Failures** ‚ö†Ô∏è MEDIUM RISK

**What happens:** File matches and transforms correctly, but fails to retrieve content from GitHub.

**Where it happens:**
- `webhook_handler_new.go` line 421-448
- If `GetFileContent()` fails, metrics are recorded but file is skipped

**Common issues:**
- ‚ùå GitHub API rate limiting (5000 requests/hour)
- ‚ùå File was renamed/moved in the same PR (GitHub shows as deleted + added)
- ‚ùå File is too large (>1MB GitHub API limit)
- ‚ùå Network timeout or transient error
- ‚ùå Authentication failure

**How to diagnose:**
```bash
# Check logs for "failed to get file content"
grep "failed to get file content" /path/to/logs

# Check metrics for files_upload_failed
curl http://your-app/metrics | grep files_upload_failed
```

---

### 4. **GitHub Upload Failures** ‚ö†Ô∏è HIGH RISK

**What happens:** File is queued for upload, but GitHub API call fails.

**Where it happens:**
- `github_write_to_target.go` lines 90-110
- If `addFilesToBranch()` or `addFilesViaPR()` fails, all files in batch fail

**Common issues:**
- ‚ùå GitHub API rate limiting
- ‚ùå Branch protection rules (can't push directly)
- ‚ùå Merge conflicts in PR
- ‚ùå Invalid commit tree (duplicate files, invalid paths)
- ‚ùå Authentication/permission errors
- ‚ùå Target branch doesn't exist

**Batch failure impact:**
```
If ONE file in a batch fails, ALL files in that batch fail!

Example:
- 50 files queued for mongodb/sample-app-java-mflix
- 1 file has invalid path
- Result: ALL 50 files fail to upload
```

**How to diagnose:**
```bash
# Check logs for "Failed to add files to target branch"
grep "Failed to add files to target branch" /path/to/logs

# Check logs for "Failed via PR path"
grep "Failed via PR path" /path/to/logs

# Check for merge conflicts
grep "merge conflicts" /path/to/logs
```

---

### 5. **Exclusion Patterns** ‚ö†Ô∏è LOW RISK (By Design)

**What happens:** Files are intentionally excluded by `exclude_patterns`.

**Where it happens:**
- Pattern matching checks exclusions before matching
- Files matching exclusion patterns are skipped

**Your config excludes:**
```yaml
exclude_patterns:
  - "\\.gitignore$"       # All .gitignore files
  - "README.md$"          # All README.md files
  - "\\.env$"             # All .env files
```

**This is BY DESIGN** - these files are handled by separate rules (rules 4, 8, 12 for .gitignore, rules 3, 7, 11 for README).

---

## How to Get 100% Confidence

### Step 1: Enable Detailed Logging (Already Done ‚úÖ)

The fixes I made added comprehensive logging:
- ‚úÖ Log every file that doesn't match any rule
- ‚úÖ Log path transformation failures
- ‚úÖ Log file retrieval failures
- ‚úÖ Log upload failures with metrics
- ‚úÖ Summary statistics (files matched vs skipped)

### Step 2: Deploy and Monitor

```bash
# Deploy the updated code
gcloud app deploy

# Watch logs in real-time
gcloud app logs tail -s default

# Or use Google Cloud Console
# https://console.cloud.google.com/logs
```

### Step 3: Trigger a Test PR

Create a test PR in `mongodb/docs-sample-apps` that changes:
1. A client file (should match rules 1, 5, 9)
2. A server file (should match rules 2, 6, 10)
3. A README file (should match rules 3, 7, 11)
4. A .gitignore file (should match rules 4, 8, 12)

### Step 4: Analyze the Logs

Look for these log entries:

```json
// Pattern matching started
{
  "message": "processing files with pattern matching",
  "file_count": 10,
  "rule_count": 12
}

// Sample files being processed
{
  "message": "sample file path",
  "index": 0,
  "path": "mflix/client/src/App.tsx"
}

// File matched a rule
{
  "message": "file matched pattern",
  "file": "mflix/client/src/App.tsx",
  "rule": "mflix-client-to-java",
  "pattern": "mflix/client/",
  "variables": {"matched_prefix": "mflix/client/", "relative_path": "src/App.tsx"}
}

// File skipped (THIS IS THE PROBLEM!)
{
  "message": "file skipped - no matching rules",
  "file": "mflix/some-file.txt",
  "status": "modified",
  "rule_count": 12
}

// Summary
{
  "message": "pattern matching complete",
  "total_files": 10,
  "files_matched": 8,
  "files_skipped": 2,
  "skipped_files": ["mflix/some-file.txt", "mflix/other-file.txt"]
}

// Upload failure (if any)
{
  "message": "Failed to add files to target branch",
  "error": "..."
}
```

### Step 5: Check Metrics

```bash
curl https://your-app.appspot.com/metrics
```

Expected output:
```json
{
  "webhooks_received": 1,
  "files_matched": 8,
  "files_uploaded": 8,
  "files_upload_failed": 0,
  "upload_success_rate": 100.0
}
```

---

## Most Likely Root Causes (Ranked)

### 1. **Pattern Matching Issues** (80% probability)

Files don't match patterns because:
- Pattern is too specific (e.g., missing files in subdirectories)
- Pattern has typo
- Files are in unexpected locations
- Regex anchors are wrong

**Fix:** Review logs for `skipped_files` array and adjust patterns.

### 2. **Batch Upload Failures** (15% probability)

One bad file causes entire batch to fail:
- Invalid path in transformation
- Merge conflict in PR
- GitHub API error

**Fix:** Add retry logic and better error handling (see recommendations below).

### 3. **File Retrieval Failures** (4% probability)

GitHub API issues:
- Rate limiting
- Large files
- Transient errors

**Fix:** Add retry logic with exponential backoff.

### 4. **Path Transformation Failures** (1% probability)

Missing variables in templates:
- Using wrong variable name
- Pattern doesn't extract expected variable

**Fix:** Validate configs with `config-validator` tool.

---

## Immediate Action Items

### 1. **Deploy the Fixes** (Do This First)

```bash
cd examples-copier
go build
gcloud app deploy
```

### 2. **Trigger a Test PR**

Create a PR in `mongodb/docs-sample-apps` with changes to various file types.

### 3. **Watch the Logs**

```bash
gcloud app logs tail -s default --format=json | jq 'select(.jsonPayload.message | contains("skipped"))'
```

### 4. **Analyze Skipped Files**

Look at the `skipped_files` array in logs. For each skipped file, ask:
- **Should this file be copied?** If yes, add/fix a pattern.
- **Is this file intentionally excluded?** If yes, document it.

### 5. **Check Upload Failures**

```bash
gcloud app logs tail -s default | grep "Failed to add files"
```

If you see failures, check:
- GitHub API rate limits
- Branch protection rules
- Merge conflicts
- Invalid file paths

---

## Recommended Improvements

### High Priority

1. **Add Retry Logic** (~2-3 days)
   ```go
   // Retry GitHub API calls with exponential backoff
   func retryWithBackoff(fn func() error, maxRetries int) error {
       for i := 0; i < maxRetries; i++ {
           err := fn()
           if err == nil {
               return nil
           }
           if isTransientError(err) {
               time.Sleep(time.Duration(math.Pow(2, float64(i))) * time.Second)
               continue
           }
           return err // Non-transient error, fail immediately
       }
       return fmt.Errorf("max retries exceeded")
   }
   ```

2. **Partial Batch Success** (~2-3 days)
   ```go
   // Instead of failing entire batch, track individual file failures
   // Upload files one-by-one or in smaller batches
   // Record which files succeeded and which failed
   ```

3. **Add Alerting** (~1 day)
   ```go
   // Alert when success rate < 95%
   if successRate < 95.0 {
       sendSlackAlert("Upload success rate dropped to %.1f%%", successRate)
   }
   ```

### Medium Priority

4. **Add Config Validation** (~1 day)
   - Validate patterns match expected files
   - Warn about unreachable patterns
   - Test path transformations

5. **Add Dry-Run Mode for PRs** (~1 day)
   - Comment on PR with what would be copied
   - Show matched files and target paths
   - Catch issues before merge

---

## Expected Outcome

After deploying the fixes and monitoring for 1-2 weeks:

**If success rate is 95%+:**
- ‚úÖ Tool is working well
- ‚úÖ 5% failures are likely edge cases (large files, rate limits, etc.)
- ‚úÖ Add retry logic to get to 98%+

**If success rate is still 70%:**
- ‚ùå Pattern matching issues (files not matching rules)
- ‚ùå Check `skipped_files` in logs
- ‚ùå Adjust patterns to match all intended files

**If success rate is < 50%:**
- ‚ùå Major issue (GitHub API, authentication, batch failures)
- ‚ùå Check for "Failed to add files" errors in logs
- ‚ùå May need architectural changes (smaller batches, different commit strategy)

---

## Next Steps

1. **Deploy the fixes** I made (metrics tracking + enhanced logging)
2. **Trigger a test PR** with various file types
3. **Analyze the logs** to see which files are skipped and why
4. **Share the logs with me** - I can help diagnose specific issues
5. **Adjust patterns** based on findings
6. **Add retry logic** if you see transient failures
7. **Monitor for 1-2 weeks** to establish baseline

---

## Questions to Answer

To help you get to 100% confidence, answer these questions:

1. **What files SHOULD be copied?**
   - All files in `mflix/` directory?
   - Only specific subdirectories?
   - Specific file types?

2. **What files SHOULD NOT be copied?**
   - `.env` files (already excluded)
   - `.gitignore` files in subdirectories (already excluded)
   - `README.md` files in subdirectories (already excluded)
   - Any others?

3. **What's the expected file count per PR?**
   - Typical PR changes 5-10 files?
   - Or 50-100 files?
   - This helps set expectations

4. **What's the actual success rate you're seeing?**
   - 70% of files copied?
   - Or 70% of PRs successful?
   - Big difference!

5. **Can you share a recent PR that had failures?**
   - PR number in `mongodb/docs-sample-apps`
   - I can analyze which files should have been copied but weren't

---

## Conclusion

Your tool is **not fundamentally broken**. The 70% rate is likely due to:
1. **Pattern matching issues** (files not matching any rule)
2. **Batch upload failures** (one bad file fails entire batch)
3. **Misleading metrics** (now fixed)

With the logging improvements I made, you'll have **full visibility** into what's happening. Deploy, test, and analyze the logs. Then we can make targeted fixes to get you to 95%+ success rate.

**Don't give up on this tool yet!** üöÄ

